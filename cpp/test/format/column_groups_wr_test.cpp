// Copyright 2023 Zilliz
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <gtest/gtest.h>

#include <random>

#include <arrow/api.h>
#include <arrow/io/api.h>
#include <arrow/testing/gtest_util.h>

#include "milvus-storage/filesystem/fs.h"
#include "milvus-storage/format/column_group_reader.h"
#include "milvus-storage/format/column_group_lazy_reader.h"
#include "milvus-storage/format/column_group_writer.h"
#include "test_env.h"

namespace milvus_storage::test {

using namespace milvus_storage::api;

class ColumnGroupsWRTest : public ::testing::TestWithParam<std::tuple<std::string, size_t>> {
  protected:
  void SetUp() override {
    // Create temporary directory for test files
    ASSERT_STATUS_OK(InitTestProperties(properties_));
    ASSERT_AND_ASSIGN(fs_, GetFileSystem(properties_));

    base_path_ = GetTestBasePath("column-group-writer-reader-test");
    ASSERT_STATUS_OK(DeleteTestDir(fs_, base_path_));
    ASSERT_STATUS_OK(CreateTestDir(fs_, base_path_));

    // Create a simple test schema with field IDs required by packed writer
    ASSERT_AND_ASSIGN(schema_, CreateTestSchema());

    // Create test data
    ASSERT_AND_ASSIGN(test_batch_, CreateTestData(schema_));

    // Get format and parallelism
    format = std::get<0>(GetParam());
    parallelism_ = std::get<1>(GetParam());

    // Initialize thread pool
    ThreadPoolHolder::WithSingleton(parallelism_);
  }

  void TearDown() override {
    // Clean up test directory
    ASSERT_STATUS_OK(DeleteTestDir(fs_, base_path_));
    ThreadPoolHolder::Release();
  }

  arrow::Result<std::vector<std::shared_ptr<ColumnGroups>>> generate_25600_rows_data(
      const std::string& format, std::shared_ptr<arrow::Schema> schema, std::array<bool, 4> projection) {
    // Test writing with SinglePolicy
    // make sure parquet will make new column group for each write
    ARROW_ASSIGN_OR_RAISE(auto rb_256_rows,
                          CreateTestData(schema /* schema */, 0, false /* randdata */, 256 /* num_rows */,
                                         1024 /* vector_dim */, 0 /* str_length */, projection /*needed_columns */));

    std::vector<std::shared_ptr<ColumnGroups>> cgsvec;
    // two files, col0 is [0~25600], col1 always (1024 * 4)B used to fill row groups
    for (int i = 0; i < 2; i++) {
      ARROW_ASSIGN_OR_RAISE(auto policy, CreateSinglePolicy(format, schema));
      auto writer = Writer::create(base_path_, schema, std::move(policy), properties_);

      // Write test data
      for (int j = 0; j < 100; ++j) {
        arrow::Int64Builder builder;
        ARROW_RETURN_NOT_OK(builder.Reserve(256));
        for (int k = 0; k < 256; ++k) {
          builder.UnsafeAppend(j * 256 + k);
        }
        std::shared_ptr<arrow::Array> id_array;
        ARROW_RETURN_NOT_OK(builder.Finish(&id_array));

        ARROW_ASSIGN_OR_RAISE(auto new_batch, rb_256_rows->SetColumn(0, arrow::field("id", arrow::int64()), id_array));
        ARROW_RETURN_NOT_OK(writer->write(new_batch));
      }

      // Close and get cgs
      ARROW_ASSIGN_OR_RAISE(auto cgs, writer->close());
      cgsvec.emplace_back(cgs);
    }

    return cgsvec;
  }

  std::pair<std::shared_ptr<ColumnGroup>, std::vector<int64_t>> generate_test_external_cg(
      const std::vector<std::shared_ptr<ColumnGroups>>& cgsvec, bool is_lance) {
    std::shared_ptr<ColumnGroup> file_cg;

    // the input should generated by `generate_25600_rows_data`
    assert(cgsvec.size() == 2);
    assert(cgsvec[0]->size() == 1);
    assert(cgsvec[1]->size() == 1);

    auto origin_cg0 = (*cgsvec[0])[0];
    auto origin_cg1 = (*cgsvec[1])[0];

    file_cg = std::make_shared<ColumnGroup>();
    file_cg->columns = origin_cg0->columns;
    file_cg->format = origin_cg0->format;
    file_cg->files = {
        ColumnGroupFile{
            .path = origin_cg0->files[0].path,
            .start_index = 1000,
            .end_index = 2000,
        },
        ColumnGroupFile{
            .path = origin_cg0->files[0].path,
            .start_index = 2000,
            .end_index = 18789,
        },
        ColumnGroupFile{
            .path = origin_cg1->files[0].path,
            .start_index = 0,
            .end_index = 5000,
        },
        ColumnGroupFile{
            .path = origin_cg1->files[0].path,
            .start_index = 5000,
            .end_index = 20000,
        },
        ColumnGroupFile{
            .path = origin_cg1->files[0].path,
            .start_index = 0,
            .end_index = 25600,
        },
    };

    if (is_lance) {
      for (size_t i = 0; i < file_cg->files.size(); ++i) {
        file_cg->files[i].path = file_cg->files[i].path + "?fragment_id=" + std::to_string(i);
      }
    }

    std::vector<int64_t> expected_ids;
    // 1 & 2. origin_cg0: 1000-18789
    for (int i = 1000; i < 18789; ++i) expected_ids.emplace_back(i);
    // 3 & 4. origin_cg1: 0-20000
    for (int i = 0; i < 20000; ++i) expected_ids.emplace_back(i);
    // 5. origin_cg1: all (0-25600)
    for (int i = 0; i < 25600; ++i) expected_ids.emplace_back(i);

    return std::make_pair(file_cg, expected_ids);
  }

  protected:
  std::string format;
  size_t parallelism_;
  std::shared_ptr<arrow::fs::FileSystem> fs_;
  std::shared_ptr<arrow::Schema> schema_;
  std::string base_path_;
  std::shared_ptr<arrow::RecordBatch> test_batch_;
  milvus_storage::api::Properties properties_;
};

TEST_P(ColumnGroupsWRTest, TestGetChunksSliced) {
  // Test writing and reading with parallelism
  int total_rows = 1000000;

  // Create multiple column groups
  std::vector<std::string> patterns = {"id|name|value|vector"};
  ASSERT_AND_ASSIGN(auto policy, CreateSchemaBasePolicy(patterns[0], format, schema_));

  auto writer = Writer::create(base_path_, schema_, std::move(policy), properties_);

  // Write test data in parallel
  for (int i = 0; i < total_rows / 1000; ++i) {
    ASSERT_AND_ASSIGN(auto batch, CreateTestData(schema_, 0, true, 1000, (i % 24) + 1));
    ASSERT_OK(writer->write(batch));
  }

  auto cgs_result = writer->close();
  ASSERT_TRUE(cgs_result.ok()) << cgs_result.status().ToString();
  auto cgs = std::move(cgs_result).ValueOrDie();

  // Read and verify data
  auto reader = Reader::create(cgs, schema_, nullptr, properties_);
  ASSERT_AND_ASSIGN(auto chunk_reader, reader->get_chunk_reader(0));

  std::vector<int64_t> row_indices;
  for (int i = 0; i < total_rows; i += 500) {
    row_indices.emplace_back(i);
  }

  ASSERT_AND_ASSIGN(auto chunk_rows_for_check, chunk_reader->get_chunk_rows());
  ASSERT_AND_ASSIGN(auto chunk_indices, chunk_reader->get_chunk_indices(row_indices));

  // all
  {
    ASSERT_AND_ASSIGN(auto chunks, chunk_reader->get_chunks(chunk_indices, parallelism_));
    ASSERT_EQ(chunks.size(), chunk_indices.size());

    for (size_t i = 0; i < chunks.size(); ++i) {
      const auto& chunk = chunks[i];
      ASSERT_NE(chunk, nullptr);
      EXPECT_EQ(chunk->num_rows(), chunk_rows_for_check[chunk_indices[i]]);
    }
  }

  // random test
  {
    std::random_device rd;
    std::mt19937 gen(rd());
    size_t random_times = 5;
    for (size_t i = 1; i <= random_times; ++i) {
      std::vector<int64_t> chunkidx_samples;

      float fraction = static_cast<float>(i) / random_times;
      size_t samples_size = static_cast<size_t>(chunk_indices.size() * fraction);

      std::sample(chunk_indices.begin(), chunk_indices.end(), std::back_inserter(chunkidx_samples), samples_size, gen);

      ASSERT_AND_ASSIGN(auto chunks, chunk_reader->get_chunks(chunkidx_samples, parallelism_));
      ASSERT_EQ(chunks.size(), chunkidx_samples.size());

      for (size_t j = 0; j < chunks.size(); ++j) {
        const auto& chunk = chunks[j];
        ASSERT_NE(chunk, nullptr);
        EXPECT_EQ(chunk->num_rows(), chunk_rows_for_check[chunkidx_samples[j]]);
      }
    }
  }
}

TEST_P(ColumnGroupsWRTest, TestStartEndIndex) {
  std::array<bool, 4> projection = {true, false, false, true};
  ASSERT_AND_ASSIGN(auto two_cols_schema, CreateTestSchema(projection));
  ASSERT_AND_ASSIGN(auto cgsvec, generate_25600_rows_data(format, two_cols_schema, projection));

  // reconstruct column group
  std::shared_ptr<ColumnGroup> file_cg;
  std::vector<int64_t> expected_ids;
  std::tie(file_cg, expected_ids) = generate_test_external_cg(cgsvec, format == LOON_FORMAT_LANCE_TABLE);

  // make sure vortex chunk rows is 256
  ASSERT_AND_ASSIGN(auto origin_chunk_rows, GetValue<uint64_t>(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS));
  EXPECT_EQ(SetValue(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS, "256"), std::nullopt);

  // reader
  ASSERT_AND_ASSIGN(auto chunk_reader, ColumnGroupReader::create(two_cols_schema, file_cg, {"id"}, properties_,
                                                                 nullptr /* key_retriever */));
  auto total_number_of_chunks = chunk_reader->total_number_of_chunks();
  auto total_rows = chunk_reader->total_rows();
  EXPECT_EQ(total_rows, expected_ids.size());

  // verification get_chunk
  {
    int64_t current_row = 0;
    for (size_t i = 0; i < total_number_of_chunks; ++i) {
      ASSERT_AND_ASSIGN(auto chunk, chunk_reader->get_chunk(i));
      ASSERT_NE(chunk, nullptr);
      auto id_array = std::static_pointer_cast<arrow::Int64Array>(chunk->column(0));
      for (int64_t j = 0; j < chunk->num_rows(); ++j) {
        ASSERT_EQ(id_array->Value(j), expected_ids[current_row])
            << "Row " << current_row << " mismatch. Chunk " << i << " row " << j;
        current_row++;
      }
    }
  }

  // verification get_chunks
  {
    std::vector<int64_t> chunk_indices;
    int64_t current_row = 0;
    for (size_t i = 0; i < total_number_of_chunks; ++i) {
      chunk_indices.push_back(i);
    }
    ASSERT_AND_ASSIGN(auto chunks, chunk_reader->get_chunks(chunk_indices, parallelism_));
    size_t total_rows = 0;
    for (size_t i = 0; i < chunks.size(); ++i) {
      total_rows += chunks[i]->num_rows();
    }

    for (size_t i = 0; i < chunks.size(); ++i) {
      const auto& chunk = chunks[i];
      ASSERT_NE(chunk, nullptr);
      auto id_array = std::static_pointer_cast<arrow::Int64Array>(chunk->column(0));
      for (int64_t j = 0; j < chunk->num_rows(); ++j) {
        ASSERT_EQ(id_array->Value(j), expected_ids[current_row])
            << "Row " << current_row << " mismatch. Chunk " << i << " row " << j;
        current_row++;
      }
    }

    ASSERT_EQ(current_row, total_rows);
  }

  // reset
  EXPECT_EQ(SetValue(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS, std::to_string(origin_chunk_rows).c_str()),
            std::nullopt);
}

TEST_P(ColumnGroupsWRTest, TestTake) {
  std::array<bool, 4> projection = {true, false, false, true};
  ASSERT_AND_ASSIGN(auto two_cols_schema, CreateTestSchema(projection));
  ASSERT_AND_ASSIGN(auto cgsvec, generate_25600_rows_data(format, two_cols_schema, projection));

  // reconstruct column group
  std::shared_ptr<ColumnGroup> file_cg;
  std::vector<int64_t> expected_ids;
  std::tie(file_cg, expected_ids) = generate_test_external_cg(cgsvec, format == LOON_FORMAT_LANCE_TABLE);

  // make sure vortex chunk rows is 256
  ASSERT_AND_ASSIGN(auto origin_chunk_rows, GetValue<uint64_t>(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS));
  EXPECT_EQ(SetValue(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS, "256"), std::nullopt);

  // reader
  ASSERT_AND_ASSIGN(auto take_reader, ColumnGroupLazyReader::create(two_cols_schema, file_cg, properties_, {"id"},
                                                                    nullptr /* key_retriever */));

  auto do_take = [parallelism = parallelism_](
                     const auto& reader,
                     const auto& row_indices) -> arrow::Result<std::shared_ptr<arrow::RecordBatch>> {
    ARROW_ASSIGN_OR_RAISE(auto table, reader->take(row_indices, parallelism));
    ARROW_ASSIGN_OR_RAISE(auto batch, table->CombineChunksToBatch());  // for test
    return batch;
  };

  auto verify_take_result = [](const auto& result_batch, const std::vector<int64_t>& expect_id,
                               const auto& row_indices) {
    ASSERT_EQ(result_batch->num_rows(), row_indices.size());
    ASSERT_EQ(result_batch->num_columns(), 1);  // only take the id
    for (size_t i = 0; i < row_indices.size(); ++i) {
      auto id_array = std::static_pointer_cast<arrow::Int64Array>(result_batch->column(0));
      ASSERT_EQ(id_array->Value(i), expect_id[row_indices[i]])
          << "Row " << i << " mismatch. Row index " << row_indices[i] << " expect " << expect_id[row_indices[i]]
          << " but " << id_array->Value(i);
    }
  };

  // all rows
  std::vector<int64_t> all_row_indices(expected_ids.size());
  std::iota(all_row_indices.begin(), all_row_indices.end(), 0);

  // random rows
  ASSERT_AND_ASSIGN(auto random_indices, GenerateSortedUniqueArray(50, expected_ids.size(), true));

  std::vector<std::vector<int64_t>> test_row_indices = {
      // take multiple rows
      {10, 500, 900},
      all_row_indices,
      random_indices,
  };

  for (const auto& row_indices : test_row_indices) {
    ASSERT_AND_ASSIGN(auto batch, do_take(take_reader, row_indices));
    verify_take_result(batch, expected_ids, row_indices);
  }

  // reset
  EXPECT_EQ(SetValue(properties_, PROPERTY_READER_LOGICAL_CHUNK_ROWS, std::to_string(origin_chunk_rows).c_str()),
            std::nullopt);
}

TEST_P(ColumnGroupsWRTest, TestFullProjection) {
  std::vector<std::string> patterns = {"id|name,value|vector"};
  ASSERT_AND_ASSIGN(auto policy, CreateSchemaBasePolicy(patterns[0], format, schema_));

  auto writer = Writer::create(base_path_, schema_, std::move(policy), properties_);
  ASSERT_OK(writer->write(test_batch_));
  ASSERT_AND_ASSIGN(auto cgs, writer->close());

  ASSERT_AND_ASSIGN(auto reader, api::ColumnGroupReader::create(schema_, (*cgs)[0], {"id", "name", "value", "vector"},
                                                                properties_, nullptr /* key_retriever */));

  ASSERT_GT(reader->total_number_of_chunks(), 0);
  ASSERT_AND_ASSIGN(auto chunk, reader->get_chunk(0));
  ASSERT_EQ(chunk->num_columns(), 2);
}

TEST_P(ColumnGroupsWRTest, TestProjection) {
  std::vector<std::string> patterns = {"id|name|value|vector"};
  ASSERT_AND_ASSIGN(auto policy, CreateSchemaBasePolicy(patterns[0], format, schema_));

  auto writer = Writer::create(base_path_, schema_, std::move(policy), properties_);
  ASSERT_OK(writer->write(test_batch_));
  ASSERT_AND_ASSIGN(auto cgs, writer->close());

  std::vector<std::vector<std::string>> valid_projections = {{"id"},
                                                             {"value"},
                                                             {"name"},
                                                             {"vector"},
                                                             {"id", "name"},
                                                             {"value", "vector"},
                                                             {"id", "value", "name", "vector"},
                                                             {"value", "id"},
                                                             {"name", "id"}};

  for (const auto& col_names : valid_projections) {
    ASSERT_AND_ASSIGN(auto reader, api::ColumnGroupReader::create(schema_, (*cgs)[0], col_names, properties_,
                                                                  nullptr /* key_retriever */));

    ASSERT_GT(reader->total_number_of_chunks(), 0);
    ASSERT_AND_ASSIGN(auto chunk, reader->get_chunk(0));
    ASSERT_EQ(chunk->num_columns(), col_names.size());

    for (int i = 0; i < chunk->num_columns(); ++i) {
      EXPECT_EQ(chunk->schema()->field(i)->name(), col_names[i]);
    }
  }

  std::vector<std::vector<std::string>> projections_with_invalid_columns = {
      {"id", "no-exist1"},
      {"id", "no-exist1", "no-exist2", "no-exist3"},
      {"id", "no-exist1", "no-exist2", "no-exist3", "no-exist4"},
      {"no-exist1", "id"},
      {"no-exist1", "no-exist2", "no-exist3", "id"},
      {"no-exist1", "no-exist2", "no-exist3", "no-exist4", "id"}};
  for (const auto& col_names : projections_with_invalid_columns) {
    ASSERT_AND_ASSIGN(auto reader, api::ColumnGroupReader::create(schema_, (*cgs)[0], col_names, properties_,
                                                                  nullptr /* key_retriever */));
    ASSERT_GT(reader->total_number_of_chunks(), 0);
    ASSERT_AND_ASSIGN(auto chunk, reader->get_chunk(0));
    ASSERT_GT(chunk->num_columns(), 0);
  }
}

INSTANTIATE_TEST_SUITE_P(ColumnGroupsWRTestP,
                         ColumnGroupsWRTest,
                         ::testing::Combine(::testing::Values(LOON_FORMAT_PARQUET, LOON_FORMAT_VORTEX),
                                            ::testing::Values(1, 4)));
}  // namespace milvus_storage::test
